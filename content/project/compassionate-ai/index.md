---
title: "Compassionate AI for Emotional Support"
summary: "A two-stage emotion-aware and trauma-informed conversational system designed to support psychological safety and safe self-disclosure."
tags:
  [
    "Human-AI Interaction",
    "Affective Computing",
    "Conversational Agents",
    "Psychological Safety",
  ]
date: 2025-09-01
image:
  filename: "featured.png" # 可以放 GIF（动图）!!
  focal_point: "Center"
links: []
---

The Compassionate AI System is a two-stage conversational architecture designed to support users experiencing emotional distress, online harm, or psychological vulnerability.
It combines computational emotion understanding with empathetic, trauma-informed response generation.

Stage 1 — Psychological State Modeling

The system analyzes user input using:

emotion classification

appraisal-based reasoning (threat, control, injustice)

crisis & trigger phrase detection

disclosure depth and distress estimation

This creates a structured internal representation of user affect that guides the downstream response generation.

Stage 2 — Compassionate Response Generation

Using the Stage-1 state signals, the AI produces responses that are:

emotionally attuned

calming and grounding

culturally sensitive

trauma-informed

safe for high-distress disclosure moments

The system integrates empathy cues, transparency statements, and variable-depth conversational strategies to maintain psychological safety.

Research Goals

This project investigates:

how users express emotion and vulnerability in AI-mediated conversations

how empathetic vs. neutral vs. non-compassionate AI behaviors influence trust

how design cues shape safe self-disclosure

what conversational strategies help reduce shame, fear, or emotional overload

Applications

The system supports studies in:

online harm recovery

digital well-being

affective HCI

responsible & emotionally intelligent AI design
